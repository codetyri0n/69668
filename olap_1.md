## OLAP DB STUFF

# OLAP ON A DISTRIBUTED DBMS
query plan is a DAG of physical operators.

factors for i/o consideration:
- table scans
- joins
- aggregations
- sorting

# COMPONENTS OF DISTRIBUTED QUERY EXECUTION
the scheduler/coordinator tracks all of the components and the proceses that are performed by them.

- persistent data
- worker nodes
- intermediate data
- shuffle nodes (optional)

## DATA CATEGORIES
# persistent data:
- source of record for the db
- modern systems assume that these data files are immutable but 
  can support updates by rewriting them.

 # intermediate data:
- short lived artifacts produced by query operators during 
  execution and then consumed by other operators.
- the amount of intermediate data generated by a query has 
  little to no correlation to amount of persistent data it 
  reads or the execution time.

## SYSTEM ARCHITECTURE
the architecture specifies the location of the db's persistent data files.
affects how nodes coordinate with each other and where they retrieve/store
objects in the db.

two approaches to this are :
- push query to data 
- pull data to query

# push query to data:
- send the query or a part of the query to the node containing the data.
- perform as much filtering and processing where the data resides before \
  transmission to the network.

# pull data to the query:
- bring the data needed for processing for the node executing the query.
- necessary when there is no resource for compute where persistent data 
  files are located.

# shared nothing architecture:
- each dbms instance has has its own CPU, memory and locally attached disk,
  the nodes only communicate with each other via network.

- db is partitioned into disjoint subsets across nodes.
  adding a new node requries physically moving data between nodes.

- since data is local, the dbms can access it through POSIX API.

- harder to scale (data movement), potentially better performance 
  and efficiency, apply filters where data resides before transfer.

# shared disk architecture:
- each node accesses a single disk via internet but has its own private 
  memory and intenral storage.

- must send messages between nodes to learn about their current state.

- instead of a POSIX API, the dbms uses a userspace API.

- scale compute layer independently from storage layer, easy to shutdown
  idle compute resources, may need to pull uncached persistent data 
  from storage to compute layer before filtering.

# shared disk implementations:
- on-prem NAS, cloud object stores 

# object stores :
- partitioned persistent data into large, immutable files used in an object store.
  all attributes of a tuple are stored in the same file in a columnar layout. (PAX)
  header (or footer) contains meta-data about columnar offsets, compression schemes,
  indexes and zone maps.

- the dbms retrieves retrieves a block's header to determine what byte ranges it needs
  to retrieve(if any).

- each cloud vendor prvoides their own proprietary API to access data (PUT, GET, DELETE).



  








